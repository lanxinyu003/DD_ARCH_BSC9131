/******************************************************************************
 Copyright © 1995-2003,2004,2005-2014 Freescale Semiconductor Inc.
 All Rights Reserved
 
 This is proprietary source code of Freescale Semiconductor Inc., and its use
 is subject to the CodeWarrior EULA.  The copyright notice above does not 
 evidence any actual or intended publication of such source code.
  
*******************************************************************************/

/******************************************************************************
 $Date: 2013/12/17 11:51:25 $
 $Id: psc9x3x.c,v 1.33 2013/12/17 11:51:25 b08551 Exp $
 $Source: /cvsdata/SmartDSP/source/arch/starcore/psc9x3x/psc9x3x.c,v $
 $Revision: 1.33 $
******************************************************************************/

/******************************************************************************
 
 @File          psc9x3x.c

 @Description   PSC9X3X-specific general initialization functions.

 @Cautions      None.
 
*//***************************************************************************/

#include "smartdsp_os_.h"
#include "os_init.h"
#include "os_.h"
#include "psc9x3x.h"
#include "psc9x3x_clocks.h"
#include "os_cache.h"
#include "os_hw_watchdogs_.h"
#include "sc3x00_mmu_.h"
#include "os_event_log_.h"
#include "hw_sem.h"
#include "att_mmu.h"

#if (OS_MULTICORE == ON)
extern os_mem_heap_t *g_os_mem_heap_shared;
extern int  g_os_num_of_shared_heaps;
#endif // OS_MULTICORE

extern os_mem_heap_t *g_os_mem_heap_local;
extern int  g_os_num_of_local_heaps;


dsp_plat_sc3850_map_t   *g_dsp_plat_map;    /* DSP SC 3850 */
psc9x3x_pa_ccsr_t       *g_dsp_pa_ccsr_map;    /* Control, Configuration and Status Registers */
psc9x3x_ccsr_t          *g_dsp_ccsr_map;    /* Control, Configuration and Status Registers */
extern uint8_t   g_dev_id;
extern uint32_t *interr_vector_file;

os_status osL2CacheInitialize(uint32_t l2cache_size);


#ifndef PSC9X3X_SC_ONLY_BSP
extern uint32_t _SHARED_CTRL_size;
#endif

extern os_log_event_t os_log_event_buffer[];
extern volatile int os_num_of_events;

#define ASSERT_AND_RETURN_ERROR(expression, err, msg) \
   if (!(expression)) {OS_ASSERT; RETURN_ERROR_MESSAGE(err, msg);}


#ifdef PSC9131_FAMILY
/*****************************************************************************/
/*
 * Update all MMU segments with start_addr - end_addr physical addresses
 * to aliased addresses according to GCR_NON_SNOOP_MAP
 */
os_status psc9x3xMmuAliasUpdate(os_phys_ptr start_addr, os_phys_ptr end_addr)
{
    struct att_mmu* adtt_mmu = _address_translation_table_mmu;      // generated by linker
    int adtt_mmu_count = (int)_address_translation_table_mmu_count; // generated by linker
    os_mmu_segment_handle   mmu_segment;
    os_mmu_attr             segment_attr;
    os_status               status;
    uint32_t alias_offset = 0;
    uint32_t snoop_val = 0;
    os_phys_ptr phys_addr;
    const uint32_t _start_addr = (uint32_t)start_addr;
    const uint32_t _end_addr   = (uint32_t)end_addr;
    int i;
 
    OS_ASSERT_COND(start_addr < end_addr);
    /* Set GCR_NON_SNOOP_MAP = 1 for aliasing 0xd000000 - 0xf0000000 to 0x20000000 - 0x40000000
     * 0 -> 0xd000000 is aliased to 0x00000000
     * 1 -> 0xd000000 is aliased to 0x20000000
     * 2 -> 0xd000000 is aliased to 0x40000000
     * 3 -> 0xd000000 is aliased to 0x60000000
     * */
    if ((_start_addr <= 0x20000000) && (_start_addr >= 0x00000000) && (_end_addr < 0x20000000) && (_end_addr >= 0x00000000))
    {
        snoop_val = 0;
    }
    else if ((_start_addr <= 0x40000000) && (_start_addr >= 0x20000000) && (_end_addr < 0x40000000) && (_end_addr >= 0x20000000))
    {
        snoop_val = 1;
    }
    else if ((_start_addr <= 0x60000000) && (_start_addr >= 0x40000000) && (_end_addr < 0x60000000) && (_end_addr >= 0x40000000))
    {
        snoop_val = 2;
    }
    else if ((_start_addr <= 0x80000000) && (_start_addr >= 0x60000000) && (_end_addr < 0x80000000) && (_end_addr >= 0x60000000))
    {
        snoop_val = 3;
    }
    else
    {
        OS_ASSERT;
        return OS_FAIL; // non valid addresses
    }
 
    SET_UINT32(g_dsp_ccsr_map->general_config.non_snoop_map, snoop_val);
    alias_offset = 0xD0000000 - 0x20000000 * snoop_val;
 
    /* map all private DSP DDR accesses to 0xd000000 - 0xf0000000 */
    for (i = 0; i < adtt_mmu_count; i++)
    {
        if ((adtt_mmu[i].physical_address >= start_addr) && (((uint32_t)adtt_mmu[i].physical_address + adtt_mmu[i].physical_size) <= _end_addr))
        {
            if (adtt_mmu[i].other & OVL_OTHER_EXEC)
            {
                // Program
                status = osMmuProgSegmentProbe(adtt_mmu[i].base_address, &mmu_segment);
                OS_ASSERT_COND(status == OS_SUCCESS);
                status = osMmuProgGetAttr(adtt_mmu[i].base_address, &segment_attr);
                OS_ASSERT_COND(status == OS_SUCCESS);
                phys_addr = (os_phys_ptr)((uint32_t)adtt_mmu[i].physical_address + alias_offset);
                status = osMmuProgSegmentCreate(mmu_segment, adtt_mmu[i].base_address, phys_addr,
                                                adtt_mmu[i].physical_size, segment_attr, NULL);
                OS_ASSERT_COND(status == OS_SUCCESS);
            }
            else
            {
                // Data
                status = osMmuDataSegmentProbe(adtt_mmu[i].base_address, &mmu_segment);
                OS_ASSERT_COND(status == OS_SUCCESS);
                status = osMmuDataGetAttr(adtt_mmu[i].base_address, &segment_attr);
                OS_ASSERT_COND(status == OS_SUCCESS);
                phys_addr = (os_phys_ptr)((uint32_t)adtt_mmu[i].physical_address + alias_offset);
                status = osMmuDataSegmentCreate(mmu_segment, adtt_mmu[i].base_address, phys_addr,
                                                adtt_mmu[i].physical_size, segment_attr, NULL);
                OS_ASSERT_COND(status == OS_SUCCESS);
            }

        }
    }
    return OS_SUCCESS;
}
#endif //  PSC9131_FAMILY

/*****************************************************************************/
static inline void psc9x3xPowerReduce()
{
}
#ifndef PSC9X3X_SC_ONLY_BSP
/*****************************************************************************/
static os_status psc9x3xMmuInit(void *virt_addr, uint32_t segment_size, bool cacheable)
{
    os_mmu_segment_handle   mmu_segment;
    uint32_t                segment_attr;
    os_status               status;
 
    status = osMmuDataSegmentProbe(virt_addr, &mmu_segment);
    if (status != OS_SUCCESS)
        status = osMmuDataSegmentFind(&mmu_segment);
    ASSERT_AND_RETURN_ERROR((status == OS_SUCCESS), status, "Unable to find available MMU segment");
 
    segment_attr  = (MMU_DATA_DEF_SYSTEM | MMU_DATA_DEF_WPERM_SUPER | MMU_DATA_DEF_RPERM_SUPER |
                     MMU_DEFAULT_VBR);

    if (segment_size <= 0x7F0000)
    {
        // Only flexible mode can handle sizes which are not power of 2 and <= 0x800000
        segment_attr |= MMU_FLEX_SEGMENT_MODEL;
    }
    else if (segment_size & (segment_size - 1))
    {
        // Non Flexible mode can handle only power of 2 sizes
        return OS_FAIL;
    }
 
    if (cacheable)
        segment_attr |= MMU_DATA_CACHEABLE_WRITEBACK | MMU_DATA_PREFETCH_ENABLE | MMU_DATA_L2_CACHEABLE_WRITEBACK ;
    else
        segment_attr |= MMU_DATA_NONCACHEABLE_WRITETHROUGH | MMU_DATA_L2_NONCACHEABLE;

    status = osMmuDataSegmentCreate(mmu_segment,
                                    virt_addr,
                                    virt_addr,
                                    segment_size,
                                    segment_attr,
                                    NULL);
    ASSERT_AND_RETURN_ERROR((status == OS_SUCCESS), status, "Unable to re-map heterogeneous MMU segment");

    status = osMmuDataSystemContextSegmentAdd(mmu_segment);
    ASSERT_AND_RETURN_ERROR((status == OS_SUCCESS), status, "Unable to add heterogeneous MMU segment to system context");

    /* Enable this segment */
    status = osMmuDataSegmentEnable(mmu_segment, TRUE);
    ASSERT_AND_RETURN_ERROR((status == OS_SUCCESS), status, "Unable to re-enable heterogeneous MMU segment");

    /* Make sure that the virtual address is mapped */
    OS_ASSERT_COND(osMmuDataVirtProbe(virt_addr) == OS_SUCCESS);
 
    return status;
}
/*****************************************************************************/
void psc9x3xHetBootInitialize()
{
#if (OS_MULTICORE == ON)
    osWaitForAllCores(); // Make sure that all cores have set heterogeneous before the semaphore is taken
#endif
    if (osGetCoreID() == osGetMasterCore())
    {
        hwSemaphoreTake(OS_HET_BOOT_HW_SEMAPHORE_NUM, OS_HET_SC_SEMAPHORE_VAL);
        while(hwSemaphoreIsTaken(OS_HET_BOOT_HW_SEMAPHORE_NUM)){}
    }
#if (OS_MULTICORE == ON)
    osWaitForAllCores(); // Don't move on until making sure that PA has been notified by semaphore
#endif
}
/*****************************************************************************/
static os_status psc9x3xHetInitialize(void *soc_het_ctrl)
{
    os_status status;
    uint32_t  pa_het_b, sc_het_b, pa_mem_size, sc_mem_size, mem_size, ctrl_link_size, heap_num;
    os_het_control_t *shared_ctrl;
    os_mem_heap_t*  heap_list;
    int i;
    void *phys_addr;
    os_het_smartdsp_log_t *smartdsp_log;
 
    shared_ctrl = (os_het_control_t *)soc_het_ctrl;
    ctrl_link_size = (uint32_t)&_SHARED_CTRL_size;
 
    // Linker must reserve 4K for Control space
    OS_ASSERT_COND(ctrl_link_size >= 0x1000);
    status = osMmuDataVirtProbe(soc_het_ctrl);
    if(status != OS_SUCCESS)
        return OS_FAIL;

    // Must be initialized by PA before SC gets there
    if((GET_UINT32(shared_ctrl->initialized.pa_initialized) != OS_HET_INITIALIZED) && (GET_UINT32(shared_ctrl->initialized.pa_initialized) != OS_HET_INITIALIZED_MULTIMODE))
        return OS_FAIL;

    // Control shared space
    READ_UINT32(mem_size, shared_ctrl->shared_ctrl_size);
    // New size can be bigger but not smaller
    OS_ASSERT_COND(ctrl_link_size <= mem_size);
    if (mem_size > ctrl_link_size)
    {
        status = psc9x3xMmuInit(soc_het_ctrl, mem_size, FALSE);
        OS_ASSERT_COND(OS_SUCCESS == status);
    }
 
    // PA shared cacheable space, aligned to cache line
    READ_MEM_UINT32(pa_het_b, shared_ctrl->pa_shared_mem.start_addr);
    OS_ASSERT_COND(IS_ALIGNED(pa_het_b, ARCH_CACHE_LINE_SIZE));
    READ_MEM_UINT32(pa_mem_size, shared_ctrl->pa_shared_mem.size);
    OS_ASSERT_COND(IS_ALIGNED(pa_mem_size, ARCH_CACHE_LINE_SIZE));
    OS_ASSERT_COND(pa_het_b < (uint32_t)soc_het_ctrl);

    // SC shared cacheable space, aligned to cache line
    READ_MEM_UINT32(sc_het_b, shared_ctrl->sc_shared_mem.start_addr);
    OS_ASSERT_COND(IS_ALIGNED(sc_het_b, ARCH_CACHE_LINE_SIZE));
    READ_MEM_UINT32(sc_mem_size, shared_ctrl->sc_shared_mem.size);
    OS_ASSERT_COND(IS_ALIGNED(sc_mem_size, ARCH_CACHE_LINE_SIZE));
    OS_ASSERT_COND(sc_het_b < (uint32_t)soc_het_ctrl);

    if (sc_het_b > pa_het_b)
    {
        /*
         * PA shared
         * =========
         * SC shared
         * =========
         * CTRL
         */
        if ((sc_mem_size > 0) && (pa_mem_size > 0))
        {
            status = psc9x3xMmuInit((void *)pa_het_b, (sc_het_b + sc_mem_size - pa_het_b), TRUE);
            OS_ASSERT_COND(OS_SUCCESS == status);
        }
        else if (sc_mem_size > 0)
        {
            status = psc9x3xMmuInit((void *)sc_het_b, sc_mem_size, TRUE);
            OS_ASSERT_COND(OS_SUCCESS == status);
        }
    }
    else
    {
        /*
         * SC shared
         * =========
         * PA shared
         * =========
         * CTRL
         */
        if ((sc_mem_size > 0) && (pa_mem_size > 0))
        {
            status = psc9x3xMmuInit((void *)sc_het_b, (pa_het_b + pa_mem_size - sc_het_b), TRUE);
            OS_ASSERT_COND(OS_SUCCESS == status);
        }
        else if (pa_mem_size > 0)
        {
            status = psc9x3xMmuInit((void *)pa_het_b, pa_mem_size, TRUE);
            OS_ASSERT_COND(OS_SUCCESS == status);
        }
    }
 
    /* SC shared cacheable heaps, even if mem_size == 0
     * the heap entry exists and still needs to be updated
     */
#if (OS_MULTICORE == ON)
    heap_list   = g_os_mem_heap_shared;
    heap_num    = (uint32_t)g_os_num_of_shared_heaps;

#else //(OS_MULTICORE == OFF)
    heap_list   = g_os_mem_heap_local;
    heap_num    = (uint32_t)g_os_num_of_local_heaps;
#endif
 
    OS_ASSERT_COMPILER_COND(heap_num >= 0);
    for(i = 0; i < heap_num; i++)
    {
        if(heap_list [i].mem_type == OS_MEM_HET_DDR1_CACHEABLE)
        {
            heap_list[i].mem_start  = (void *)(sc_het_b + sc_mem_size);
            heap_list[i].mem_size   = sc_mem_size;
#if (OS_MULTICORE == OFF)
            osHeapInit(heap_list[i].mem_start, heap_list[i].mem_size, (os_mem_type)heap_list[i].mem_type);
#endif
            break;
        }
    }
 
    /* SC debug location for PA post-mortem analysis
     */
    status = osMmuDataVirtToPhys((const os_virt_ptr)os_log_event_buffer, &phys_addr);
    OS_ASSERT_COND(OS_SUCCESS == status);
 
    if (shared_ctrl->smartdsp_debug != NULL)
    {
        smartdsp_log = &(*shared_ctrl->smartdsp_debug)[osGetCoreID()];
        smartdsp_log->base_address = (uintptr_t)phys_addr;
        smartdsp_log->size = (uint32_t)(os_num_of_events * sizeof(os_log_event_t));
 
        status = osMmuDataVirtToPhys((const os_virt_ptr)&g_os_last_error, &phys_addr);
        OS_ASSERT_COND(OS_SUCCESS == status);
        smartdsp_log->last_error = (uint32_t *)phys_addr;
    }
    shared_ctrl->initialized.sc_initialized = shared_ctrl->initialized.pa_initialized;

    return status;
}
#endif // PSC9X3X_SC_ONLY_BSP

/*****************************************************************************/

os_status psc9x3xInitialize(float clock_in,
                            void    *qbus,
                            void    *pa_sys_regs,
                            void    *sys_regs,
                            void    *ctrl_base,
                            bool     data_cache,
                            bool     prog_cache,
                            bool     l2_cache,
                            unsigned int l2cache_size
                            ,platform_init_params_t* platform_params
                            )

{
    os_status status;

    OS_ASSERT_COND(IS_ALIGNED(&interr_vector_file, ALIGNED_4096_BYTES));
 
    g_dsp_plat_map     = (dsp_plat_sc3850_map_t *)qbus;
    g_dsp_pa_ccsr_map  = (psc9x3x_pa_ccsr_t *)pa_sys_regs;
    g_dsp_ccsr_map     = (psc9x3x_ccsr_t *)sys_regs;

#if (OS_MULTICORE == ON)
    g_core_info.soc_core_num        = (uint8_t)((GET_UINT32(g_dsp_plat_map->mmu.m_pir) & 0x00FF0000) >> 16);
    g_core_info.cluster_core_num    = g_core_info.soc_core_num;
    g_core_info.cluster_num         = 0;
    g_core_info.cluster_master_core = g_core_info.soc_master_core;
    /* g_core_info.soc_master_core;   // gets set in osInitializeKernel() */
#endif  // OS_MULTICORE
 
    g_dev_id = 0x0;
 
    osCacheDataEnable(data_cache);
    osCacheDataGlobalLock(!data_cache);
 
    osCacheProgEnable(prog_cache);
    osCacheProgGlobalLock(!prog_cache);
 
    status = osL2CacheInitialize(l2cache_size);
    if (status != OS_SUCCESS)
    {
        OS_ASSERT;
        return status;
    }
    osCacheL2UnifiedEnable(l2_cache);
    osCacheL2UnifiedGlobalLock(!l2_cache);
 
    sc3x00MmuInitPlatform(platform_params);
 
    psc9x3xPowerReduce();


    status = psc9x3xInitializeClocks(clock_in);
    if (status != OS_SUCCESS)
    {
        OS_ASSERT;
        return status;
    }
 
 
#ifndef PSC9X3X_SC_ONLY_BSP
    status = psc9x3xHetInitialize(ctrl_base);
    OS_ASSERT_COND(OS_SUCCESS == status);
#else
    VAR_UNUSED(ctrl_base);
#endif
 
    return status;
}
/*****************************************************************************/
uint32_t socHwWdtNmiSource()
{
    return (uint32_t)((GET_UINT32(g_dsp_ccsr_map->general_config.gir1.gir) >> 24) & 0xFF);
}

